<br>

# ✍️ Derivatives - Calculus I - Resolution of Mathematics Exercises
#### <p align="center"> AI Data Science - PUCSP University - Math Repository - [Professor Eric Bacconi Gonçalves](https://www.linkedin.com/in/eric-bacconi-423137/)

<br>

https://github.com/user-attachments/assets/e77310b2-7d55-48a2-96c2-f729cf434b75

<br>

Welcome to the **Derivatives - Calculus I** repository! This repository is a comprehensive guide designed to assist students, educators, and enthusiasts in mastering the resolution of mathematics exercises related to derivatives in Calculus I.


## 1. Introduction to the Repository

This repository aims to provide a structured approach to learning derivatives, starting from the basic concepts to more advanced applications. Whether you're preparing for exams, brushing up on calculus, or exploring the role of calculus in data science, this resource will be invaluable.

## 2. Fundamental Concepts

In this section, we cover the foundational concepts necessary for understanding derivatives, including:

- **Limits and Continuity**: The building blocks of derivatives.
- **Definition of a Derivative**: What it means and how it's calculated.
- **Basic Differentiation Rules**: Techniques such as the power rule, product rule, quotient rule, and chain rule.
- **Higher-Order Derivatives**: Understanding the second derivative and beyond.
- **Common Functions**: Differentiating functions like polynomials, exponentials, logarithms, and trigonometric functions.

## 3. Why Derivatives are Important for AI Data Scientists

Derivatives are not just a mathematical curiosity; they play a crucial role in the field of data science and artificial intelligence (AI). This section discusses:

- **Optimization**: How derivatives help in finding minima and maxima, which are key in training machine learning models.
- **Gradient Descent**: The backbone of many learning algorithms, using derivatives to optimize model parameters.
- **Regularization**: Preventing overfitting by penalizing excessive complexity, guided by derivative-based techniques.
- **Neural Networks**: Backpropagation relies heavily on derivatives for updating weights and biases in deep learning models.

**[Understanding these applications highlights the importance of derivatives in the development and optimization of AI models.]()**


## 4. Exercises

This section provides practice exercises to help you apply the concepts you've learned. Below are the exercise solutions in LaTeX format:


### [Exercises: Find the following derivatives]() ☟

## [Exercicise A:]() 

### Given function $\( f(x) = x^2 + 3x + 2 \)$, find the derivative of \( f(x) \) with respect to \( x \), and evaluate it at \( x = 1 \).


Calculate, $\( f'(x) \)$

Substitute $\( x = 1 \)$ into $\( f'(x) \)$

`Latex Code ☟`

```latex
\begin{enumerate}
    \item Calculate \( f'(x) \).
    \item Substitute \( x = 1 \) into \( f'(x) \).
\end{enumerate}
```

Solution:

$\ f'(x)$ = $\frac{d}{dx}(x^2 + 3x + 2) = 2x + 3\$

$\ f'(1)$ = $2(1) + 3 = 5\$


`Latex Code ☟`

```latex
\ f'(x) = \frac{d}{dx}(x^2 + 3x + 2) = 2x + 3\

\ f'(1) = 2(1) + 3 = 5\
``` 

## [Exercicise B:]() 

### Given Function: $\( f(x) = x \cdot e^x \)$

For this function, we use the product rule, which states that the derivative of a product of two functions is the first function times the derivative of the second, plus the second function times the derivative of the first.

So, we have:

$\ f'(x) = \frac{d}{dx}(x) \cdot e^x + x \cdot \frac{d}{dx}(e^x)\$


$\ f'(x) = 1 \cdot e^x + x \cdot e^x\$


$\ f'(x) = e^x + x \cdot e^x\$

<br>


`Latex Code ☟`

```latex
\ f'(x) = \frac{d}{dx}(x) \cdot e^x + x \cdot \frac{d}{dx}(e^x)\
```

```latex
\ f'(x) = 1 \cdot e^x + x \cdot e^x\
```

```latex
\ f'(x) = e^x + x \cdot e^x\
```









